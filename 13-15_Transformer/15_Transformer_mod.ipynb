{"cells":[{"cell_type":"markdown","metadata":{"id":"tknSEXfMeLHB"},"source":["# Seq2seq 프로젝트: 한영 번역기 만들기"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9225,"status":"ok","timestamp":1700137563249,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"},"user_tz":-540},"id":"KDJ1SY3lPlWe","outputId":"864f326a-fd42-4a76-b801-8c651c8a88ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 1s (9,568 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 120882 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n"]}],"source":["# 한글폰트 설치: 실행후 런타임 재시작 필요\n","!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"]},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","\n","def run_all_cells_after_restart():\n","    display(Javascript('''\n","    var idx = Jupyter.notebook.get_selected_index();\n","    var count = Jupyter.notebook.ncells();\n","    for (var i=idx+1; i<count; i++) {\n","        Jupyter.notebook.execute_cells([i]);\n","    }\n","    '''))\n","\n","# 런타임 재시작\n","import os\n","def restart_runtime():\n","    os.kill(os.getpid(), 9)\n","\n","# 런타임 재시작\n","restart_runtime()\n","\n","# 현재 셀 이후의 모든 셀 실행\n","run_all_cells_after_restart()"],"metadata":{"id":"WnptCYHpHCaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1700137564325,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"},"user_tz":-540},"id":"MglIYUTrPpAD","outputId":"38e1f88d-dac8-4a01-ed58-1a67854a9afc"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47800 (\\N{HANGUL SYLLABLE MOM}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44172 (\\N{HANGUL SYLLABLE GE}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 53412 (\\N{HANGUL SYLLABLE KI}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50752 (\\N{HANGUL SYLLABLE WA}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n","WARNING:matplotlib.font_manager:findfont: Font family 'NanumBarunGothic' not found.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# 한글 표시 여부 확인\n","import matplotlib.pyplot as plt\n","plt.rcParams['font.family'] = 'NanumBarunGothic' # 나눔바른고딕 적용하기\n","\n","# 예제 데이터\n","heights = [150, 160, 170, 180, 190]  # 키 (cm)\n","weights = [50, 60, 70, 80, 90]       # 몸무게 (kg)\n","\n","# 산점도 그리기\n","plt.scatter(heights, weights)\n","\n","# 제목 및 레이블 추가\n","plt.title(\"키와 몸무게\")\n","plt.xlabel(\"키 (cm)\")\n","plt.ylabel(\"몸무게 (kg)\")\n","\n","# 그래프 표시\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"F7v_DaPKfCoL"},"source":["## 데이터 정제"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3092,"status":"ok","timestamp":1700137567411,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"},"user_tz":-540},"id":"SyGlHAI0T4gL","outputId":"295f7f1a-a05c-4132-8a48-2fd9edd8e95e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'korean-parallel-corpora'...\n","remote: Enumerating objects: 173, done.\u001b[K\n","remote: Counting objects: 100% (42/42), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 173 (delta 18), reused 0 (delta 0), pack-reused 131\u001b[K\n","Receiving objects: 100% (173/173), 20.48 MiB | 12.60 MiB/s, done.\n","Resolving deltas: 100% (61/61), done.\n"]}],"source":["# 학습 데이터 다운로드\n","!git clone https://github.com/jungyeul/korean-parallel-corpora.git\n","\n","# 한-영 뉴스 코퍼스 압축해제\n","!mkdir kor-eng-train\n","!tar -xzf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.train.tar.gz -C kor-eng-train/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1700137568045,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"},"user_tz":-540},"id":"bpxdJEsAfv9B","outputId":"26d11cf1-56c7-4655-dc47-52850f3394b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data Size in ./kor-eng-train/korean-english-park.train.en: 94123\n","Examples:\n",">> Much of personal computing is about \"can you top this?\"\n",">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n","Data Size in ./kor-eng-train/korean-english-park.train.ko: 94123\n","Examples:\n",">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"]}],"source":["# 데이터 확인\n","def read_and_print_examples(file_path, num_examples=100, step=20):\n","    with open(file_path, \"r\", encoding='utf-8') as f:\n","        raw = f.read().splitlines()\n","\n","    print(f\"Data Size in {file_path}: {len(raw)}\")\n","    print(\"Examples:\")\n","\n","    for sen in raw[:num_examples:step]:\n","        print(\">>\", sen)\n","\n","# 영어 파일 읽기 및 출력\n","read_and_print_examples(\"./kor-eng-train/korean-english-park.train.en\")\n","\n","# 한국어 파일 읽기 및 출력\n","read_and_print_examples(\"./kor-eng-train/korean-english-park.train.ko\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hm0UE7zahO3G","executionInfo":{"status":"ok","timestamp":1700137708395,"user_tz":-540,"elapsed":140353,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"57540f6b-03a4-4c8b-bd78-62d9c1ed6b87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 138, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91\u001b[K\n","Receiving objects: 100% (138/138), 1.72 MiB | 4.48 MiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n","Installing konlpy.....\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2023-11-16 12:26:21--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKIFYQ6OI&Signature=F84gywyxb31GbvxlBK58aNTdgzg%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEUaCXVzLWVhc3QtMSJHMEUCIC%2F5Jb%2FrdRFShkRdDyZchCRGTVF0ywJ%2FSRLZYVa14Tp8AiEAnrN7G44%2BhW9EdwErxjKy7g6KJ18gipywUsHgyVnSpKAqsAIIjf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDHh8Dd1rY5Av97kdjiqEAu6KKF4tjJIeyjicnc0XRNA%2Fu9ixmepLxBLP%2BexNxFSuLE85Xj6vTCpzbiTwqqUOEJSLdhXpIcZ3Ofl35ZYZFe4C%2B95JEjMt7NhYHWWYg0e6qF7sS3JDAXcsZZ%2F2u1LmKpymHfTNsxTH4CabBOKFh9ovtGAYRmMKYUz%2FgKWJbr%2FHxYcUntc6KRn5YZaBGD3ib1ny6aJRBFFJv5tcwVAI5ptb92vuhMtF4rfmgAe7a1bTaOVco943JMkFWoeiB7pv9TR85gWYE5cRgkKVvaf9wjZ1B4%2FI7soxSB2LAz1rk6dFThPz4mDEdE%2B9VEkD1JIS%2FaQqp1DFLq06G%2Fv8bDRWWai98PwdMNWO2KoGOp0B4ZaE5PT3HCg6Oiz1rMW%2FAmAQqub%2FlQy4G4TODemgfJIlvW%2Bl%2BwuSzTcNFWvmX3%2F%2FbU1pPR75yjkJUoS1JhspFFpVFRhc6mBJIqdrdsu65Kb2nFXfo9hrkNFt6FRcrLhQUi%2BOsasyOR4P0CsbP9aYq83Fk17Dvy6rumc3GN0lzx9BpNFhVMSc5cnIsyNnJTQxBNysB51iGcZivy136Q%3D%3D&Expires=1700138589 [following]\n","--2023-11-16 12:26:22--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKIFYQ6OI&Signature=F84gywyxb31GbvxlBK58aNTdgzg%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEUaCXVzLWVhc3QtMSJHMEUCIC%2F5Jb%2FrdRFShkRdDyZchCRGTVF0ywJ%2FSRLZYVa14Tp8AiEAnrN7G44%2BhW9EdwErxjKy7g6KJ18gipywUsHgyVnSpKAqsAIIjf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDHh8Dd1rY5Av97kdjiqEAu6KKF4tjJIeyjicnc0XRNA%2Fu9ixmepLxBLP%2BexNxFSuLE85Xj6vTCpzbiTwqqUOEJSLdhXpIcZ3Ofl35ZYZFe4C%2B95JEjMt7NhYHWWYg0e6qF7sS3JDAXcsZZ%2F2u1LmKpymHfTNsxTH4CabBOKFh9ovtGAYRmMKYUz%2FgKWJbr%2FHxYcUntc6KRn5YZaBGD3ib1ny6aJRBFFJv5tcwVAI5ptb92vuhMtF4rfmgAe7a1bTaOVco943JMkFWoeiB7pv9TR85gWYE5cRgkKVvaf9wjZ1B4%2FI7soxSB2LAz1rk6dFThPz4mDEdE%2B9VEkD1JIS%2FaQqp1DFLq06G%2Fv8bDRWWai98PwdMNWO2KoGOp0B4ZaE5PT3HCg6Oiz1rMW%2FAmAQqub%2FlQy4G4TODemgfJIlvW%2Bl%2BwuSzTcNFWvmX3%2F%2FbU1pPR75yjkJUoS1JhspFFpVFRhc6mBJIqdrdsu65Kb2nFXfo9hrkNFt6FRcrLhQUi%2BOsasyOR4P0CsbP9aYq83Fk17Dvy6rumc3GN0lzx9BpNFhVMSc5cnIsyNnJTQxBNysB51iGcZivy136Q%3D%3D&Expires=1700138589\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.58.65, 3.5.29.240, 54.231.169.81, ...\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.58.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.67MB/s    in 0.4s    \n","\n","2023-11-16 12:26:22 (3.67 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2023-11-16 12:28:04--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHF22KQUD&Signature=6%2FVOxKHnskewID%2BrrU%2BarxUJU5Q%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEUaCXVzLWVhc3QtMSJGMEQCICChC0aznwHHgMS7iXCF4HT7qtm30SX5TVK%2BZrZskfl%2BAiApBFOM06Jl7mHyXwxZaJ4nH4%2B%2Fio5%2B1jFdEzxLk3biYSqwAgiN%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMLzRka1xO5h4HG4qoKoQC%2BqvZpa3stt2Qhx3bMhqby7t2skGAvseZHE9ZAavfgDHRFhz7fx13age2SoRYQkHcr71D990MPydizQYYsAEF6PTL1ae15HSMqtAykmjOHv96lFEZuKNCJ%2BzBxqJqlvkzAWEaIcC2MDHsef2BEv2ZVzElcwFGbVgienzQfyBiWyyxMyj6mugKYUSokVFx8kFwoBLInYe8XL%2BjvXv%2FXms0zGZsczsdQpatWlDS8uxrb5g2duEGcp%2F22r%2F%2F%2BNYCocU7niU3jDQEUzQDP5rMe7cm0peS4czeW4%2Fx8CocqjoDaMfTY%2B1wyNb4fNvKdT%2BkEXqC8M6ErxBY%2FdCgireUlsYGHJvHkrYwtY%2FYqgY6ngGk3G%2BbSlSk7nsAXuWbuaQepirXvwf%2BlgZualpIs%2FpBCvi2ZdzL4tay2XJQgy%2BCo3j%2BxgBptM%2F16E9YCy2LqKzxuBjSt0r42f9EqJJx75UZrILTcW0n04xWQeYQ6W4EakPUbDHttnZR200i13tKgVX%2BpjmhnzO1y8Rcriy20xm4QyLp%2BsZGz9tYgtAqyXCY6SNrldyEJ4%2FyQETNXBJUjg%3D%3D&Expires=1700138685 [following]\n","--2023-11-16 12:28:04--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHF22KQUD&Signature=6%2FVOxKHnskewID%2BrrU%2BarxUJU5Q%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEUaCXVzLWVhc3QtMSJGMEQCICChC0aznwHHgMS7iXCF4HT7qtm30SX5TVK%2BZrZskfl%2BAiApBFOM06Jl7mHyXwxZaJ4nH4%2B%2Fio5%2B1jFdEzxLk3biYSqwAgiN%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMLzRka1xO5h4HG4qoKoQC%2BqvZpa3stt2Qhx3bMhqby7t2skGAvseZHE9ZAavfgDHRFhz7fx13age2SoRYQkHcr71D990MPydizQYYsAEF6PTL1ae15HSMqtAykmjOHv96lFEZuKNCJ%2BzBxqJqlvkzAWEaIcC2MDHsef2BEv2ZVzElcwFGbVgienzQfyBiWyyxMyj6mugKYUSokVFx8kFwoBLInYe8XL%2BjvXv%2FXms0zGZsczsdQpatWlDS8uxrb5g2duEGcp%2F22r%2F%2F%2BNYCocU7niU3jDQEUzQDP5rMe7cm0peS4czeW4%2Fx8CocqjoDaMfTY%2B1wyNb4fNvKdT%2BkEXqC8M6ErxBY%2FdCgireUlsYGHJvHkrYwtY%2FYqgY6ngGk3G%2BbSlSk7nsAXuWbuaQepirXvwf%2BlgZualpIs%2FpBCvi2ZdzL4tay2XJQgy%2BCo3j%2BxgBptM%2F16E9YCy2LqKzxuBjSt0r42f9EqJJx75UZrILTcW0n04xWQeYQ6W4EakPUbDHttnZR200i13tKgVX%2BpjmhnzO1y8Rcriy20xm4QyLp%2BsZGz9tYgtAqyXCY6SNrldyEJ4%2FyQETNXBJUjg%3D%3D&Expires=1700138685\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.114.161, 52.217.236.137, 54.231.139.49, ...\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.114.161|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  35.4MB/s    in 1.3s    \n","\n","2023-11-16 12:28:06 (35.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n","https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n","Done\n","Install mecab-python\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n","NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n","블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n","light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n","문제를 해결해주신 combacsa님 감사합니다.\n"]}],"source":["# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","# !bash ./Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab_light_220429.sh"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"fpiAQiA_gXjp","executionInfo":{"status":"ok","timestamp":1700139219036,"user_tz":-540,"elapsed":914,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["import re\n","\n","# 공통 전처리 함수\n","\n","kor_path = \"./kor-eng-train/korean-english-park.train.ko\"\n","eng_path = \"./kor-eng-train/korean-english-park.train.en\"\n","\n","# 데이터 정제 및 토큰화\n","def clean_corpus(kor_path, eng_path):\n","    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n","    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n","    assert len(kor) == len(eng)\n","\n","    cleaned_corpus = []\n","    seen_pairs = set()\n","\n","    for k, e in zip(kor, eng):\n","        if (k, e) not in seen_pairs:\n","            pair = f\"{k}\\t{e}\"  # 한국어 문장과 영어 문장을 탭으로 구분하여 저장\n","            cleaned_corpus.append(pair)\n","            seen_pairs.add((k, e))\n","\n","    return cleaned_corpus\n","\n","cleaned_corpus = clean_corpus(kor_path, eng_path)\n","\n","def preprocess_sentence(sentence):\n","    # 모든 입력을 소문자로 변환합니다.\n","    sentence = sentence.lower()\n","\n","    # 알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n","    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence)\n","\n","    # 문장부호 양옆에 공백을 추가합니다.\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","\n","    # 문장 앞뒤의 불필요한 공백을 제거합니다.\n","    sentence = sentence.strip()\n","\n","    return sentence"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRU4x5GGFSCF","executionInfo":{"status":"ok","timestamp":1700137716783,"user_tz":-540,"elapsed":7950,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"268ee1a6-cee0-46ef-bbfd-c2e58678a3ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W43JRf5QpH7L","executionInfo":{"status":"ok","timestamp":1700139253800,"user_tz":-540,"elapsed":31850,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"8fad9718-c02b-4c0e-cf47-d2a35b271c27"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":31}],"source":["import sentencepiece as spm\n","import os\n","\n","# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n","def generate_tokenizer(corpus, vocab_size, lang=\"ko\", pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n","    model_name = f\"{lang}_spm\"\n","\n","    # 텍스트 파일로 코퍼스 저장\n","    temp_file = f\"{model_name}.temp\"\n","    with open(temp_file, 'w', encoding='utf-8') as f:\n","        for line in corpus:\n","            f.write(f'{line}\\n')\n","\n","    # SentencePiece 모델 학습\n","    spm.SentencePieceTrainer.Train(\n","        f'--input={temp_file} --model_prefix={model_name} '\n","        f'--vocab_size={vocab_size} --character_coverage=1.0 '\n","        f'--pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id}'\n","    )\n","\n","    # 생성된 모델 로드\n","    tokenizer = spm.SentencePieceProcessor()\n","    tokenizer.Load(f\"{model_name}.model\")\n","\n","    # 임시 파일 삭제\n","    os.remove(temp_file)\n","\n","    return tokenizer\n","\n","\n","SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n","\n","eng_corpus = []\n","kor_corpus = []\n","\n","for pair in cleaned_corpus:\n","    k, e = pair.split(\"\\t\")\n","\n","    kor_corpus.append(preprocess_sentence(k))\n","    eng_corpus.append(preprocess_sentence(e))\n","\n","ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n","en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n","en_tokenizer.set_encode_extra_options(\"bos:eos\")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["795f6c5663b54888aadded00f664c66f","0f25642d7edd418eabc6b6a573ecbd1b","b35ddae80d554f679a57f0c7aeb96a7b","9a737a8c11ec43d2a342def4c3a36f25","9f4341a2a2d0477a979fa979d7d05281","5dc3d9f548b8416293e480ba689cee37","fab1599e09434379b77b66f697c0396f","cb55b4401e994c4da611f79e9a965da8","04ed4b61558a4026b2f312588d6930f7","917c1e5376d1493b8d7cb5d1d083528e","17ade1ba33414656aafa23a2563cc39c"]},"id":"uAV8XpihpH7L","executionInfo":{"status":"ok","timestamp":1700139260901,"user_tz":-540,"elapsed":6316,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"d1998876-5993-4318-de42-950ab69a8863"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78968 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795f6c5663b54888aadded00f664c66f"}},"metadata":{}}],"source":["import tensorflow as tf\n","from tqdm.notebook import tqdm    # 진행 과정을 보기 위한 도구\n","\n","src_corpus = []\n","tgt_corpus = []\n","\n","assert len(kor_corpus) == len(eng_corpus)\n","\n","# 토큰의 길이가 50 이하인 문장만 남깁니다.\n","for idx in tqdm(range(len(kor_corpus))):\n","    src_tok = ko_tokenizer.EncodeAsIds(kor_corpus[idx])  # 한국어 문장 토큰화\n","    tgt_tok = en_tokenizer.EncodeAsIds(eng_corpus[idx])  # 영어 문장 토큰화\n","\n","    if len(src_tok) <= 50 and len(tgt_tok) <= 50:  # 토큰 길이가 50 이하인 경우만 선택\n","        src_corpus.append(src_tok)\n","        tgt_corpus.append(tgt_tok)\n","\n","# 패딩처리를 완료하여 학습용 데이터를 완성합니다.\n","enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n","dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLCl1u3IODHr","executionInfo":{"status":"ok","timestamp":1700139260901,"user_tz":-540,"elapsed":8,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"6a454fdc-29db-4ce9-9999-790b92dd193e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1:\n","소스 시퀀스 (패딩 포함): [ 1066   357   527   487     7  1298  1841     9  1219   220  2473   937\n","    29 10466     8 19851     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0]\n","타겟 시퀀스 (패딩 포함): [   1  342   11 1356 7453   14   22   56  107  105  245   50  337    2\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","소스 문장 (패딩 제외): ▁개인 용 ▁컴퓨터 ▁사용 의 ▁상당 ▁부분 은 ▁이것 보다 ▁뛰어 날 ▁수 ▁있느냐 ▁ ?\n","타겟 문장 (패딩 제외): <s> ▁much ▁of ▁personal ▁comput ing ▁is ▁about ▁can ▁you ▁top ▁this ▁? </s>\n","\n","Sample 10000:\n","소스 시퀀스 (패딩 포함): [4611  721 3781   23 7559   13 3231   13 1579   10 2790  154 4867    6\n"," 1894   11 9224   28  166    4    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","타겟 시퀀스 (패딩 포함): [   1    4 8967   14  612   11  507   35 1730   10  528   12   89  312\n","    6  194 5096    6 3671   13 2087    5    2    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","소스 문장 (패딩 제외): ▁식료품 ▁가격 ▁급등 으로 ▁아이티 ▁, ▁방글라데시 ▁, ▁이집트 를 ▁포함해 ▁일부 ▁국가에서 는 ▁폭력사태 가 ▁발생하기 도 ▁했다 ▁.\n","타겟 문장 (패딩 제외): <s> ▁the ▁skyrocket ing ▁cost ▁of ▁food ▁has ▁trigger ed ▁violence ▁in ▁some ▁countries ▁, ▁including ▁haiti ▁, ▁bangladesh ▁and ▁egypt ▁. </s>\n","\n","Sample 30000:\n","소스 시퀀스 (패딩 포함): [2122 6825 2995   23  810   13 1937 2995   23 2167  979    4    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","타겟 시퀀스 (패딩 포함): [   1   31  815   21    6   53   41  129   10   12 5466    6   13   56\n","    6   12 2060  130    5    2    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","소스 문장 (패딩 제외): ▁이밖에 ▁크로아티아 ▁내전 으로 ▁만명 ▁, ▁코소보 ▁내전 으로 ▁만명이 ▁숨졌다 ▁.\n","타겟 문장 (패딩 제외): <s> ▁an ▁estimate d ▁, ▁people ▁were ▁kill ed ▁in ▁croatia ▁, ▁and ▁about ▁, ▁in ▁kosov o ▁. </s>\n","\n","Sample 50000:\n","소스 시퀀스 (패딩 포함): [   43  5605 10075    58  5978  2943     6  2458     7 14230     5  1589\n","     4     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0]\n","타겟 시퀀스 (패딩 포함): [    1     4  2694    35     9  1135 12875     5  5626    40    15  4247\n","     7    27  4560     2     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0]\n","소스 문장 (패딩 제외): ▁이번 ▁경매에 ▁낙찰 된 ▁블루 ▁다이아몬드 는 ▁왕 의 ▁혈통 을 ▁가졌다 ▁.\n","타겟 문장 (패딩 제외): <s> ▁the ▁diamond ▁has ▁a ▁royal ▁lineage ▁. ▁christi e ▁s ▁trace s ▁it ▁thus </s>\n","\n"]}],"source":["# 원하는 인덱스의 데이터에 대해서만 수행\n","indices_to_check = [1, 10000, 30000, 50000]\n","\n","for index in indices_to_check:\n","    src_sequence = enc_train[index - 1]  # 인덱스는 1부터 시작하므로 -1\n","    tgt_sequence = dec_train[index - 1]  # 인덱스는 1부터 시작하므로 -1\n","\n","    # 패딩을 제외하고 원래 문장으로 변환\n","    src_tokens = [ko_tokenizer.IdToPiece(int(token)) for token in src_sequence if token != 0]\n","    tgt_tokens = [en_tokenizer.IdToPiece(int(token)) for token in tgt_sequence if token != 0]\n","\n","    print(f\"Sample {index}:\")\n","    print(\"소스 시퀀스 (패딩 포함):\", src_sequence)\n","    print(\"타겟 시퀀스 (패딩 포함):\", tgt_sequence)\n","    print(\"소스 문장 (패딩 제외):\", \" \".join(src_tokens))\n","    print(\"타겟 문장 (패딩 제외):\", \" \".join(tgt_tokens))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"k1_AI_rVoC36"},"source":["## \b트랜스포머 설계"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"NEgQdZqxF2Ga","executionInfo":{"status":"ok","timestamp":1700137781645,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["import numpy as np\n","\n","# 포지셔널 인코딩\n","def positional_encoding(pos, d_model):\n","    def cal_angle(position, i):\n","        return position / np.power(10000, int(i) / d_model)\n","\n","    def get_posi_angle_vec(position):\n","        return [cal_angle(position, i) for i in range(d_model)]\n","\n","    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n","    return sinusoid_table"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YtqjfPbcF4y3","executionInfo":{"status":"ok","timestamp":1700137781645,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["import tensorflow as tf\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.W_q = tf.keras.layers.Dense(d_model)\n","        self.W_k = tf.keras.layers.Dense(d_model)\n","        self.W_v = tf.keras.layers.Dense(d_model)\n","\n","        self.linear = tf.keras.layers.Dense(d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask):\n","        d_k = tf.cast(K.shape[-1], tf.float32)\n","        QK = tf.matmul(Q, K, transpose_b=True)\n","\n","        scaled_qk = QK / tf.math.sqrt(d_k)\n","\n","        if mask is not None: scaled_qk += (mask * -1e9)\n","\n","        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n","        out = tf.matmul(attentions, V)\n","\n","        return out, attentions\n","\n","\n","    def split_heads(self, x):\n","        batch_size = x.shape[0]\n","        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n","\n","        return split_x\n","\n","    def combine_heads(self, x):\n","        batch_size = x.shape[0]\n","        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n","        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n","\n","        return combined_x\n","\n","\n","    def call(self, Q, K, V, mask):\n","        WQ = self.W_q(Q)\n","        WK = self.W_k(K)\n","        WV = self.W_v(V)\n","\n","        WQ_splits = self.split_heads(WQ)\n","        WK_splits = self.split_heads(WK)\n","        WV_splits = self.split_heads(WV)\n","\n","        out, attention_weights = self.scaled_dot_product_attention(\n","            WQ_splits, WK_splits, WV_splits, mask)\n","\n","        out = self.combine_heads(out)\n","        out = self.linear(out)\n","\n","        return out, attention_weights"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"EVSAKV2MPBUL","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":6,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# Position-wise FFN\n","\n","class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n","    def __init__(self, d_model, d_ff):\n","        super(PoswiseFeedForwardNet, self).__init__()\n","        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n","        self.w_2 = tf.keras.layers.Dense(d_model)\n","\n","    def call(self, x):\n","        out = self.w_1(x)\n","        out = self.w_2(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9dJvA6kAl2V2","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, n_heads, d_ff, dropout):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n","        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n","\n","        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout = tf.keras.layers.Dropout(dropout)\n","\n","    def call(self, x, mask):\n","\n","        \"\"\"\n","        Multi-Head Attention\n","        \"\"\"\n","        residual = x\n","        out = self.norm_1(x)\n","        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n","        out = self.dropout(out)\n","        out += residual\n","\n","        \"\"\"\n","        Position-Wise Feed Forward Network\n","        \"\"\"\n","        residual = out\n","        out = self.norm_2(out)\n","        out = self.ffn(out)\n","        out = self.dropout(out)\n","        out += residual\n","\n","        return out, enc_attn"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0R4ugOCIrL3j","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n","\n","        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout = tf.keras.layers.Dropout(dropout)\n","\n","    def call(self, x, enc_out, causality_mask, padding_mask):\n","\n","        \"\"\"\n","        Masked Multi-Head Attention\n","        \"\"\"\n","        residual = x\n","        out = self.norm_1(x)\n","        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n","        out = self.dropout(out)\n","        out += residual\n","\n","        \"\"\"\n","        Multi-Head Attention\n","        \"\"\"\n","        residual = out\n","        out = self.norm_2(out)\n","        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n","        out = self.dropout(out)\n","        out += residual\n","\n","        \"\"\"\n","        Position-Wise Feed Forward Network\n","        \"\"\"\n","        residual = out\n","        out = self.norm_3(out)\n","        out = self.ffn(out)\n","        out = self.dropout(out)\n","        out += residual\n","\n","        return out, dec_attn, dec_enc_attn"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Mj_kw8jjS54i","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# 인코더와 디코더 클래스\n","class Encoder(tf.keras.Model):\n","    def __init__(self,\n","                 n_layers,\n","                 d_model,\n","                 n_heads,\n","                 d_ff,\n","                 dropout):\n","        super(Encoder, self).__init__()\n","        self.n_layers = n_layers\n","        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n","                        for _ in range(n_layers)]\n","\n","    def call(self, x, mask):\n","        out = x\n","\n","        enc_attns = list()\n","        for i in range(self.n_layers):\n","            out, enc_attn = self.enc_layers[i](out, mask)\n","            enc_attns.append(enc_attn)\n","\n","        return out, enc_attns\n","\n","class Decoder(tf.keras.Model):\n","    def __init__(self,\n","                 n_layers,\n","                 d_model,\n","                 n_heads,\n","                 d_ff,\n","                 dropout):\n","        super(Decoder, self).__init__()\n","        self.n_layers = n_layers\n","        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n","                            for _ in range(n_layers)]\n","\n","\n","    def call(self, x, enc_out, causality_mask, padding_mask):\n","        out = x\n","\n","        dec_attns = list()\n","        dec_enc_attns = list()\n","        for i in range(self.n_layers):\n","            out, dec_attn, dec_enc_attn = \\\n","            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n","\n","            dec_attns.append(dec_attn)\n","            dec_enc_attns.append(dec_enc_attn)\n","\n","        return out, dec_attns, dec_enc_attns"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"0e2CtJ0XTCpB","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","    def __init__(self,\n","                    n_layers,\n","                    d_model,\n","                    n_heads,\n","                    d_ff,\n","                    src_vocab_size,\n","                    tgt_vocab_size,\n","                    pos_len,\n","                    dropout=0.2,\n","                    shared=True):\n","        super(Transformer, self).__init__()\n","        self.d_model = tf.cast(d_model, tf.float32)\n","\n","        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n","        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n","\n","        self.pos_encoding = positional_encoding(pos_len, d_model)\n","        self.dropout = tf.keras.layers.Dropout(dropout)\n","\n","        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n","        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n","\n","        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n","\n","        self.shared = shared\n","\n","        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n","\n","    def embedding(self, emb, x):\n","        seq_len = x.shape[1]\n","        out = emb(x)\n","\n","        if self.shared: out *= tf.math.sqrt(self.d_model)\n","\n","        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n","        out = self.dropout(out)\n","\n","        return out\n","\n","\n","    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n","        enc_in = self.embedding(self.enc_emb, enc_in)\n","        dec_in = self.embedding(self.dec_emb, dec_in)\n","\n","        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n","\n","        dec_out, dec_attns, dec_enc_attns = \\\n","        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n","\n","        logits = self.fc(dec_out)\n","\n","        return logits, enc_attns, dec_attns, dec_enc_attns"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"5mTLweDJWEPL","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# Masking\n","\n","def generate_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    return seq[:, tf.newaxis, tf.newaxis, :]\n","\n","def generate_causality_mask(src_len, tgt_len):\n","    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n","    return tf.cast(mask, tf.float32)\n","\n","def generate_masks(src, tgt):\n","    enc_mask = generate_padding_mask(src)\n","    dec_mask = generate_padding_mask(tgt)\n","\n","    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n","    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n","\n","    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n","    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n","\n","    return enc_mask, dec_enc_mask, dec_mask"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"AP3QaV1uXDDb","executionInfo":{"status":"ok","timestamp":1700137781646,"user_tz":-540,"elapsed":5,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# # 마스크 작동방식 확인\n","# import matplotlib.pyplot as plt\n","\n","# batch, length = 16, 20\n","# src_padding = 5\n","# tgt_padding = 15\n","\n","# src_pad = tf.zeros(shape=(batch, src_padding))\n","# tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n","\n","# sample_data = tf.ones(shape=(batch, length))\n","\n","# sample_src = tf.concat([sample_data, src_pad], axis=-1)\n","# sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n","\n","# enc_mask, dec_enc_mask, dec_mask = \\\n","# generate_masks(sample_src, sample_tgt)\n","\n","# fig = plt.figure(figsize=(7, 7))\n","\n","# ax1 = fig.add_subplot(131)\n","# ax2 = fig.add_subplot(132)\n","# ax3 = fig.add_subplot(133)\n","\n","# ax1.set_title('1) Encoder Mask')\n","# ax2.set_title('2) Encoder-Decoder Mask')\n","# ax3.set_title('3) Decoder Mask')\n","\n","# ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n","# ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n","# ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n","\n","# plt.show()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"vyDUc-leXV_f","executionInfo":{"status":"ok","timestamp":1700138014474,"user_tz":-540,"elapsed":2269,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","# 커스텀 학습률 조정자\n","class CustomLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomLearningRateScheduler, self).__init__()\n","        self.d_model = tf.cast(d_model, tf.float32)  # d_model을 float32 타입으로 변환\n","        self.warmup_steps = tf.cast(warmup_steps, tf.float32)  # warmup_steps를 float32 타입으로 변환\n","\n","    def __call__(self, step):\n","        step = tf.cast(step, tf.float32)  # step을 float32 타입으로 변환\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","learning_rate = CustomLearningRateScheduler(d_model=512)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,\n","                                     beta_1=0.9,\n","                                     beta_2=0.98,\n","                                     epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"R_A1ayTXxzb5"},"source":["## 훈련"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"y_eK0kjrZ39f","executionInfo":{"status":"ok","timestamp":1700138019310,"user_tz":-540,"elapsed":1361,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# 트랜스포머 선언\n","\n","# Hyperparameters\n","N_LAYERS = 2\n","D_MODEL = 512\n","N_HEADS = 8\n","D_FF = 2048\n","POS_LEN = 200  # 이 값은 데이터셋에 따라 조정될 수 있습니다.\n","DROPOUT = 0.1\n","\n","# Transformer 인스턴스 생성\n","transformer = Transformer(\n","    n_layers=N_LAYERS,\n","    d_model=D_MODEL,\n","    n_heads=N_HEADS,\n","    d_ff=D_FF,\n","    src_vocab_size=SRC_VOCAB_SIZE,\n","    tgt_vocab_size=TGT_VOCAB_SIZE,\n","    pos_len=POS_LEN,\n","    dropout=DROPOUT\n",")\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"MftGuotY0M5a","executionInfo":{"status":"ok","timestamp":1700138020918,"user_tz":-540,"elapsed":385,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# 손실함수 정의\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Qm5vs83opH7O","executionInfo":{"status":"ok","timestamp":1700138023367,"user_tz":-540,"elapsed":287,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# train_step 함수 완성\n","@tf.function()\n","def train_step(src, tgt, model, optimizer):\n","    gold = tgt[:, 1:]\n","\n","    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n","\n","    with tf.GradientTape() as tape:\n","        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n","        loss = loss_function(gold, predictions[:, :-1])\n","\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    return loss, enc_attns, dec_attns, dec_enc_attns"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"GoR8vBXNgBWK","executionInfo":{"status":"ok","timestamp":1700138024490,"user_tz":-540,"elapsed":2,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":["# Attention 시각화 함수\n","\n","def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n","    def draw(data, ax, x=\"auto\", y=\"auto\"):\n","        import seaborn\n","        seaborn.heatmap(data,\n","                        square=True,\n","                        vmin=0.0, vmax=1.0,\n","                        cbar=False, ax=ax,\n","                        xticklabels=x,\n","                        yticklabels=y)\n","\n","    for layer in range(0, 2, 1):\n","        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n","        print(\"Encoder Layer\", layer + 1)\n","        for h in range(4):\n","            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n","        plt.show()\n","\n","    for layer in range(0, 2, 1):\n","        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n","        print(\"Decoder Self Layer\", layer+1)\n","        for h in range(4):\n","            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n","        plt.show()\n","\n","        print(\"Decoder Src Layer\", layer+1)\n","        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n","        for h in range(4):\n","            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n","        plt.show()\n","\n","# 번역 생성 함수\n","\n","def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n","    sentence = preprocess_sentence(sentence)\n","\n","    pieces = src_tokenizer.encode_as_pieces(sentence)\n","    tokens = src_tokenizer.encode_as_ids(sentence)\n","\n","    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n","                                                           maxlen=enc_train.shape[-1],\n","                                                           padding='post')\n","\n","    ids = []\n","    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n","    for i in range(dec_train.shape[-1]):\n","        enc_padding_mask, combined_mask, dec_padding_mask = \\\n","        generate_masks(_input, output)\n","\n","        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n","        model(_input,\n","              output,\n","              enc_padding_mask,\n","              combined_mask,\n","              dec_padding_mask)\n","\n","        predicted_id = \\\n","        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n","\n","        if tgt_tokenizer.eos_id() == predicted_id:\n","            result = tgt_tokenizer.decode_ids(ids)\n","            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n","\n","        ids.append(predicted_id)\n","        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n","\n","    result = tgt_tokenizer.decode_ids(ids)\n","\n","    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n","\n","# 번역 생성 및 Attention 시각화 결합\n","\n","def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n","    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n","    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n","\n","    print('Input: %s' % (sentence))\n","    print('Predicted translation: {}'.format(result))\n","\n","    if plot_attention:\n","        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":982,"referenced_widgets":["8b77878e5b024ee581c821a0b29edcd7","cf2c5a416a8b4790bc6f15bb61cc85b5","342630c7a32442a38d0765ebd5efb4a6","ceb14cbc45c141e2b919934e1e7d0a4c","5cc0183e56a14328b130705fff725350","07bc249f9b6f44e288d6f32256a45c6d","cdc7eb9ace204afe93a4457579d2e086","dd271e28c4354e638103f6043d86df3c","fce6323855fe4823acd2812b8dee14d5","f38c6deb7ab74862b573e4d9dbb0f24f","ee1827a430694c469baea2d4aeed5634","33f4197e1f9944f687612ed15f576006","ac11bf8246ed42128db382b5b753b967","acf70ff75d6b45d28b51efec3c97debc","4a07dd53c0c74d06bc929f323a4ec862","98cb394a2185442a8e99cdc8feec1bcd","2980f6548a884ad8a44255f807dd1bca","78d69cb205c445b98cb98de96af3ada0","7cfccaaef81b484695c2af20310c53d2","b1aabedd43534eb78990cd2f00eef26b","1618d9cd301a493c80e9c2fc464f5e42","80d801b77a794b139967334618672ecd","535f17004b664426bb67f06333de96b7","889aaf2403bd43ad99b5d0cd2c43c5a6","e3bcdcaa11434c16b83e5af8806282d6","fc65e36ed06c41cbbe7704600015162a","e3e5170687864a049861414cdde1de9b","6ebd06253b9e4314bdd9cb98cfa76b53","d870923dff2c4a8cb898fdfe2d3396bf","b28f332b90f3477e92fa3876c7d75336","66398ce1ef6a498f92d3c0d242e2314f","091eb1d7cd594ee0bbe3844bbf83d5dc","5c4b196af23e4e21bc8f1874d438fa6f","9bd29d060c734cc4bf8dc00b07c94acb","2d3be6108bca4d59818b22ced7c814ed","e207c6f054734016a543b36f0c4daf18","f4109f80377e4c85bc9a6e62d90c9db6","7c25183a373f428d8998772bc38f7e9a","9d7b6d454d0140098fd2cc33bf4ca7df","770f504585fd48a7b9a523bee193a095","d05e9c0f5a3f494e8cdd7679c5a61627","13a148965ed44cc8ba48e68f7526ab19","e5b1fa1cc1bd4558b8367b7a8eb91c0c","697f730084e04ae1bb5972762058961b"]},"id":"DEvaYi04pH7O","executionInfo":{"status":"error","timestamp":1700138840643,"user_tz":-540,"elapsed":813145,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}},"outputId":"93e007af-3b93-49cc-8238-ad077c2b8e40"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b77878e5b024ee581c821a0b29edcd7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input: 오바마는 대통령이다.\n","Predicted translation: 영한사전 약어표\n","Input: 시민들은 도시 속에 산다.\n","Predicted translation: 영한사전 약어표 한영사전 약어표\n","Input: 커피는 필요 없다.\n","Predicted translation: 영한사전 약어표 한영사전 약어표\n","Input: 일곱 명의 사망자가 발생했다.\n","Predicted translation: 영한사전 약어표 한영사전 약어표\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33f4197e1f9944f687612ed15f576006"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input: 오바마는 대통령이다.\n","Predicted translation: cnn한글뉴스\n","Input: 시민들은 도시 속에 산다.\n","Predicted translation: cnn 오피니언리서치의 형은 일 현지시간 cnn 이수지 joins\n","Input: 커피는 필요 없다.\n","Predicted translation: cnn 오피니언리서치가 찾은 검색어\n","Input: 일곱 명의 사망자가 발생했다.\n","Predicted translation: cnn 오피니언리서치의 형은 일 현지시간 cnn 이수지 joins\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"535f17004b664426bb67f06333de96b7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input: 오바마는 대통령이다.\n","Predicted translation: 원문기사보기\n","Input: 시민들은 도시 속에 산다.\n","Predicted translation: 원문기사보기\n","Input: 커피는 필요 없다.\n","Predicted translation: 원문기사보기\n","Input: 일곱 명의 사망자가 발생했다.\n","Predicted translation: 원문기사보기\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd29d060c734cc4bf8dc00b07c94acb"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-2bf40e283cf9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         train_step(enc_train[idx:idx+BATCH_SIZE],\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mdec_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 학습\n","\n","import random\n","from tqdm import tqdm_notebook\n","\n","BATCH_SIZE = 64\n","EPOCHS = 20\n","\n","examples = [\n","            \"오바마는 대통령이다.\",\n","            \"시민들은 도시 속에 산다.\",\n","            \"커피는 필요 없다.\",\n","            \"일곱 명의 사망자가 발생했다.\"\n","]\n","\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","\n","    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n","    random.shuffle(idx_list)\n","    t = tqdm(idx_list)\n","\n","    for (batch, idx) in enumerate(t):\n","        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n","        train_step(enc_train[idx:idx+BATCH_SIZE],\n","                    dec_train[idx:idx+BATCH_SIZE],\n","                    transformer,\n","                    optimizer)\n","\n","        total_loss += batch_loss\n","\n","        t.set_description_str('Epoch %2d' % (epoch + 1))\n","        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n","\n","    for example in examples:\n","        translate(example, transformer, ko_tokenizer, en_tokenizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VurmOIWCe9AN","executionInfo":{"status":"aborted","timestamp":1700137786254,"user_tz":-540,"elapsed":4,"user":{"displayName":"Junghyun Joseph Kim","userId":"06138359960746591941"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"N9l_B4n9pH7P"},"source":["## 테스트"]},{"cell_type":"markdown","metadata":{"id":"yyytXWcppH7P"},"source":["# 회고\n","\n","모델 작성을 마치고, 텐서 형태가 맞지 않는다는 에러가 발생해서 GPT의 도움으로 디버깅을 시도했다. 차원 숫자를 모두 출력해서 확인하는 방식으로 코드 수정을 제안받아서 계속 몇 차례 출력문을 집어넣다가, 'enc_in'이 들어가야 할 자리에 'emc_in'이 들어가 있다는 것을 발견했다.\n","\n","학습을 위해서 코드를 직접 따라치는 과정에서 오타가 생긴 모양이었다.\n","\n","GPT가 없었다면 아마 발견도 못했을 것 같은데... 학습을 위해서 직접 코딩을 할 때에는 타이핑 후에 무결한 코드를 붙여넣는 방식으로 마무리를 하는 게 좋겠다는 생각이 든다.\n","\n","그런데 안타깝게도 문제는 오타를 수정해도 해결되지 않았다. 결국 코드를 다시 처음부터 가져와서 고치는 과정을 수행했고, 그러자 문제없이 잘 작동이 되었다.\n","\n","그리고.. 또다시 오류가 발생했다.\n","학습 중에 번역결과를 출력하는데 영문이 아니라 계속 한글이 나온다.\n","\n","거슬러올라가보니 최초에 코퍼스 경로 입력 시에 영문과 한글을 뒤집어놨다. (환장..)\n","뭐 이런 실수를 다 하나.. 싶은데 내가 한 실수라서 누워서 침뱉기다."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1-jXkrdT10x90XCbksfAirJDaVAt5SCCu","timestamp":1700137134093},{"file_id":"15Qi7PtG8dmPCX8sdX1LGzuyZ_ey48ILu","timestamp":1700096413854}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"795f6c5663b54888aadded00f664c66f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f25642d7edd418eabc6b6a573ecbd1b","IPY_MODEL_b35ddae80d554f679a57f0c7aeb96a7b","IPY_MODEL_9a737a8c11ec43d2a342def4c3a36f25"],"layout":"IPY_MODEL_9f4341a2a2d0477a979fa979d7d05281"}},"0f25642d7edd418eabc6b6a573ecbd1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dc3d9f548b8416293e480ba689cee37","placeholder":"​","style":"IPY_MODEL_fab1599e09434379b77b66f697c0396f","value":"100%"}},"b35ddae80d554f679a57f0c7aeb96a7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb55b4401e994c4da611f79e9a965da8","max":78968,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04ed4b61558a4026b2f312588d6930f7","value":78968}},"9a737a8c11ec43d2a342def4c3a36f25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_917c1e5376d1493b8d7cb5d1d083528e","placeholder":"​","style":"IPY_MODEL_17ade1ba33414656aafa23a2563cc39c","value":" 78968/78968 [00:05&lt;00:00, 14907.80it/s]"}},"9f4341a2a2d0477a979fa979d7d05281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dc3d9f548b8416293e480ba689cee37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fab1599e09434379b77b66f697c0396f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb55b4401e994c4da611f79e9a965da8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04ed4b61558a4026b2f312588d6930f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"917c1e5376d1493b8d7cb5d1d083528e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17ade1ba33414656aafa23a2563cc39c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b77878e5b024ee581c821a0b29edcd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf2c5a416a8b4790bc6f15bb61cc85b5","IPY_MODEL_342630c7a32442a38d0765ebd5efb4a6","IPY_MODEL_ceb14cbc45c141e2b919934e1e7d0a4c"],"layout":"IPY_MODEL_5cc0183e56a14328b130705fff725350"}},"cf2c5a416a8b4790bc6f15bb61cc85b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07bc249f9b6f44e288d6f32256a45c6d","placeholder":"​","style":"IPY_MODEL_cdc7eb9ace204afe93a4457579d2e086","value":"Epoch  1: 100%"}},"342630c7a32442a38d0765ebd5efb4a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd271e28c4354e638103f6043d86df3c","max":1139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fce6323855fe4823acd2812b8dee14d5","value":1139}},"ceb14cbc45c141e2b919934e1e7d0a4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f38c6deb7ab74862b573e4d9dbb0f24f","placeholder":"​","style":"IPY_MODEL_ee1827a430694c469baea2d4aeed5634","value":" 1139/1139 [04:21&lt;00:00,  5.36it/s, Loss 6.8144]"}},"5cc0183e56a14328b130705fff725350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07bc249f9b6f44e288d6f32256a45c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdc7eb9ace204afe93a4457579d2e086":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd271e28c4354e638103f6043d86df3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fce6323855fe4823acd2812b8dee14d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f38c6deb7ab74862b573e4d9dbb0f24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee1827a430694c469baea2d4aeed5634":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33f4197e1f9944f687612ed15f576006":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac11bf8246ed42128db382b5b753b967","IPY_MODEL_acf70ff75d6b45d28b51efec3c97debc","IPY_MODEL_4a07dd53c0c74d06bc929f323a4ec862"],"layout":"IPY_MODEL_98cb394a2185442a8e99cdc8feec1bcd"}},"ac11bf8246ed42128db382b5b753b967":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2980f6548a884ad8a44255f807dd1bca","placeholder":"​","style":"IPY_MODEL_78d69cb205c445b98cb98de96af3ada0","value":"Epoch  2: 100%"}},"acf70ff75d6b45d28b51efec3c97debc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cfccaaef81b484695c2af20310c53d2","max":1139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1aabedd43534eb78990cd2f00eef26b","value":1139}},"4a07dd53c0c74d06bc929f323a4ec862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1618d9cd301a493c80e9c2fc464f5e42","placeholder":"​","style":"IPY_MODEL_80d801b77a794b139967334618672ecd","value":" 1139/1139 [03:30&lt;00:00,  5.46it/s, Loss 5.2535]"}},"98cb394a2185442a8e99cdc8feec1bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2980f6548a884ad8a44255f807dd1bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d69cb205c445b98cb98de96af3ada0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cfccaaef81b484695c2af20310c53d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1aabedd43534eb78990cd2f00eef26b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1618d9cd301a493c80e9c2fc464f5e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d801b77a794b139967334618672ecd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"535f17004b664426bb67f06333de96b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_889aaf2403bd43ad99b5d0cd2c43c5a6","IPY_MODEL_e3bcdcaa11434c16b83e5af8806282d6","IPY_MODEL_fc65e36ed06c41cbbe7704600015162a"],"layout":"IPY_MODEL_e3e5170687864a049861414cdde1de9b"}},"889aaf2403bd43ad99b5d0cd2c43c5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ebd06253b9e4314bdd9cb98cfa76b53","placeholder":"​","style":"IPY_MODEL_d870923dff2c4a8cb898fdfe2d3396bf","value":"Epoch  3: 100%"}},"e3bcdcaa11434c16b83e5af8806282d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b28f332b90f3477e92fa3876c7d75336","max":1139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66398ce1ef6a498f92d3c0d242e2314f","value":1139}},"fc65e36ed06c41cbbe7704600015162a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091eb1d7cd594ee0bbe3844bbf83d5dc","placeholder":"​","style":"IPY_MODEL_5c4b196af23e4e21bc8f1874d438fa6f","value":" 1139/1139 [03:30&lt;00:00,  5.43it/s, Loss 4.5732]"}},"e3e5170687864a049861414cdde1de9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ebd06253b9e4314bdd9cb98cfa76b53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d870923dff2c4a8cb898fdfe2d3396bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b28f332b90f3477e92fa3876c7d75336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66398ce1ef6a498f92d3c0d242e2314f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"091eb1d7cd594ee0bbe3844bbf83d5dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c4b196af23e4e21bc8f1874d438fa6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bd29d060c734cc4bf8dc00b07c94acb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d3be6108bca4d59818b22ced7c814ed","IPY_MODEL_e207c6f054734016a543b36f0c4daf18","IPY_MODEL_f4109f80377e4c85bc9a6e62d90c9db6"],"layout":"IPY_MODEL_7c25183a373f428d8998772bc38f7e9a"}},"2d3be6108bca4d59818b22ced7c814ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d7b6d454d0140098fd2cc33bf4ca7df","placeholder":"​","style":"IPY_MODEL_770f504585fd48a7b9a523bee193a095","value":"Epoch  4:  58%"}},"e207c6f054734016a543b36f0c4daf18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d05e9c0f5a3f494e8cdd7679c5a61627","max":1139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13a148965ed44cc8ba48e68f7526ab19","value":665}},"f4109f80377e4c85bc9a6e62d90c9db6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5b1fa1cc1bd4558b8367b7a8eb91c0c","placeholder":"​","style":"IPY_MODEL_697f730084e04ae1bb5972762058961b","value":" 665/1139 [02:02&lt;01:26,  5.46it/s, Loss 4.0336]"}},"7c25183a373f428d8998772bc38f7e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d7b6d454d0140098fd2cc33bf4ca7df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"770f504585fd48a7b9a523bee193a095":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d05e9c0f5a3f494e8cdd7679c5a61627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a148965ed44cc8ba48e68f7526ab19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5b1fa1cc1bd4558b8367b7a8eb91c0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"697f730084e04ae1bb5972762058961b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}