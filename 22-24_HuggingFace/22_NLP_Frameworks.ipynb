{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNHM7CbFGiyhTG5w4OWwHcK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c5fc91e5bc604d81a61525556d80a975":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26f08597932e40f689c4bb14a7c68115","IPY_MODEL_d12c9e5c424740baa0e58fb8ba57a755","IPY_MODEL_ab2912b290b64d63ae02a1e22fc3dcba"],"layout":"IPY_MODEL_a51c29d1071e4e98b730e8154c4a0232"}},"26f08597932e40f689c4bb14a7c68115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd5e8e7ae34849c898b8e20560f7bcb6","placeholder":"​","style":"IPY_MODEL_b6efc32f543b45e59733fb006d1ca4f4","value":"Map: 100%"}},"d12c9e5c424740baa0e58fb8ba57a755":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edfa8184ec0b4921af6c3e121551a18a","max":1043,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c09f69b83dd848d982737694ed067147","value":1043}},"ab2912b290b64d63ae02a1e22fc3dcba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c65adbe34e04e14bd952a5a5509cd13","placeholder":"​","style":"IPY_MODEL_694aa711691a4ed3a99362a3efb6bfa1","value":" 1043/1043 [00:00&lt;00:00, 10117.70 examples/s]"}},"a51c29d1071e4e98b730e8154c4a0232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5e8e7ae34849c898b8e20560f7bcb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6efc32f543b45e59733fb006d1ca4f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edfa8184ec0b4921af6c3e121551a18a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c09f69b83dd848d982737694ed067147":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c65adbe34e04e14bd952a5a5509cd13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"694aa711691a4ed3a99362a3efb6bfa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 허깅페이스 모델 사용"],"metadata":{"id":"iDAYANhOtWU7"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DtuX0PsbNfT","executionInfo":{"status":"ok","timestamp":1701751523765,"user_tz":-540,"elapsed":6969,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"62addd1d-4594-493f-aaa0-0d6790b007a4"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n","\n","All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9978194236755371}]"]},"metadata":{},"execution_count":3}],"source":["from transformers import pipeline\n","\n","classifier = pipeline('sentiment-analysis', framework='tf')\n","classifier('We are very happy to include pipeline into the transformers repository.')"]},{"cell_type":"code","source":["# 감정분석 테스트\n","classifier('오늘은 기분이 좋아. 랄랄라 랄랄랄랄라~ 마음속 깊이, 간직한 꿈이, 이루어질 것 같아요!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHtoMlzIs3bg","executionInfo":{"status":"ok","timestamp":1701751524581,"user_tz":-540,"elapsed":824,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"da499b40-ee76-4b26-f1df-b624a0ec687d"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.8796578645706177}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## 허깅 페이스에서 모델을 불러오는 방식\n"],"metadata":{"id":"BuxTRVKptT3z"}},{"cell_type":"code","source":["# 모델명 지정 방식\n","\n","from transformers import TFBertForPreTraining\n","model_fpmethod = TFBertForPreTraining.from_pretrained('bert-base-cased') # ID를 입력\n","\n","print(model_fpmethod.__class__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epGR2WIBte4p","executionInfo":{"status":"ok","timestamp":1701751527742,"user_tz":-540,"elapsed":3163,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"c560bd13-e25e-4e98-87aa-9931b3307843"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertForPreTraining.\n","\n","All the weights of TFBertForPreTraining were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.bert.modeling_tf_bert.TFBertForPreTraining'>\n"]}]},{"cell_type":"code","source":["# AutoModel 사용\n","from transformers import TFAutoModel\n","model_am = TFAutoModel.from_pretrained(\"bert-base-cased\")\n","\n","print(model_am.__class__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JhsIHfUt_A7","executionInfo":{"status":"ok","timestamp":1701751529837,"user_tz":-540,"elapsed":2097,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"7e192ac2-1a2c-4b58-a669-54ace09fae36"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.bert.modeling_tf_bert.TFBertModel'>\n"]}]},{"cell_type":"markdown","source":["\n","## 토크나이저"],"metadata":{"id":"Y59ddKA7teyp"}},{"cell_type":"code","source":["# 특정 모델의 토크나이저를 지정하는 방법\n","from transformers import BertTokenizer\n","tokenizer_specific = BertTokenizer.from_pretrained('bert-base-cased')"],"metadata":{"id":"z7BT5o60tesr","executionInfo":{"status":"ok","timestamp":1701751529838,"user_tz":-540,"elapsed":6,"user":{"displayName":"­김정현","userId":"07015025296255556159"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 토크나이저 자동 지정\n","from transformers import AutoTokenizer\n","tokenizer_ID = AutoTokenizer.from_pretrained('bert-base-cased') # 모델 로드 시 사용한 ID 지정"],"metadata":{"id":"DjlexmKJ3NAH","executionInfo":{"status":"ok","timestamp":1701751529838,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김정현","userId":"07015025296255556159"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 토크나이저 실행 결과\n","encoded = tokenizer_specific(\"This is Test for aiffel\")\n","print(f'specified encoded: {encoded}')\n","\n","encoded_2 = tokenizer_ID(\"This is Test for aiffel_2\")\n","print(f'ID-based encoded: {encoded_2}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vgx-8NGI3cMh","executionInfo":{"status":"ok","timestamp":1701751529838,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"b3de5304-8762-4160-a9b8-ee34bf8f6884"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["specified encoded: {'input_ids': [101, 1188, 1110, 5960, 1111, 170, 11093, 1883, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","ID-based encoded: {'input_ids': [101, 1188, 1110, 5960, 1111, 170, 11093, 1883, 168, 123, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}]},{"cell_type":"code","source":["# 문장 분할 메서드\n","bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","bert_tokens = bert_tokenizer.tokenize(\"This is Test for aiffel\")\n","print(\"BertTokenizer로 토큰화된 결과:\", bert_tokens)\n","\n","# AutoTokenizer 사용\n","auto_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n","auto_tokens = auto_tokenizer.tokenize(\"This is Test for aiffel\")\n","print(\"AutoTokenizer로 토큰화된 결과:\", auto_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBnVqgTH3479","executionInfo":{"status":"ok","timestamp":1701751530382,"user_tz":-540,"elapsed":547,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"089e5514-36aa-44a5-f2a2-b1adef724e8e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["BertTokenizer로 토큰화된 결과: ['This', 'is', 'Test', 'for', 'a', '##iff', '##el']\n","AutoTokenizer로 토큰화된 결과: ['This', 'is', 'Test', 'for', 'a', '##iff', '##el']\n"]}]},{"cell_type":"code","source":["# batch 단위 토크나이징도 가능\n","\n","batch_sentences = [\"Hello I'm a single sentence\",\n","                    \"And another sentence\",\n","                    \"And the very very last one\"]\n","\n","encoded_batch = tokenizer_ID(batch_sentences)\n","print(encoded_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NIZXwPn5S6q","executionInfo":{"status":"ok","timestamp":1701751530383,"user_tz":-540,"elapsed":9,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"f2863bd4-78cb-4654-9470-5aa54b143e39"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102], [101, 1262, 1330, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}]},{"cell_type":"code","source":["# 다양한 옵션 설정\n","\n","batch = tokenizer_ID(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n","print(batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3GBAwCc5dyB","executionInfo":{"status":"ok","timestamp":1701751530383,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"f7059297-63c8-4a1d-e6d5-f82849f6fa56"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n","array([[ 101, 8667,  146,  112,  182,  170, 1423, 5650,  102],\n","       [ 101, 1262, 1330, 5650,  102,    0,    0,    0,    0],\n","       [ 101, 1262, 1103, 1304, 1304, 1314, 1141,  102,    0]],\n","      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n","array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 0, 0, 0, 0],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}\n"]}]},{"cell_type":"markdown","source":["## Config: 하이퍼 파라미터를 포함한 전반적인 설정을 처리하는 설정 클래스"],"metadata":{"id":"U4UUq8pOteli"}},{"cell_type":"code","source":["# 모델 지정 기반의 설정 불러오기\n","from transformers import BertConfig\n","\n","config = BertConfig.from_pretrained(\"bert-base-cased\")\n","print(config.__class__)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KtnUih6ktecY","executionInfo":{"status":"ok","timestamp":1701751530383,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"dbe1b2db-07a0-4a28-862c-41db87377b5a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.bert.configuration_bert.BertConfig'>\n","BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n"]}]},{"cell_type":"code","source":["# AutoConfig\n","from transformers import AutoConfig\n","\n","config = AutoConfig.from_pretrained(\"bert-base-cased\")\n","print(config.__class__)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giRmR2JZ51-j","executionInfo":{"status":"ok","timestamp":1701751530383,"user_tz":-540,"elapsed":6,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"d912d754-c259-425d-b375-394f84e1ff01"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.bert.configuration_bert.BertConfig'>\n","BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n"]}]},{"cell_type":"code","source":["# 생성된 모델의 설정 불러오기\n","print(f'사전훈련 모델에서 불러온 경우\\n{model_fpmethod.config}')\n","print(f'오토모델\\n{model_am.config}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoNcy9La6DJ0","executionInfo":{"status":"ok","timestamp":1701751530383,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"356fdd6c-018c-4851-b70d-a406205f57b5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["사전훈련 모델에서 불러온 경우\n","BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","오토모델\n","BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n"]}]},{"cell_type":"markdown","source":["## Trainer: 학습을 진행하는 클래스"],"metadata":{"id":"9FMMCmI7td1I"}},{"cell_type":"code","source":["# 자연어처리 연구 및 애플리케이션 개발용 허깅페이스 라이브러리 설치\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqnP79vkApYM","executionInfo":{"status":"ok","timestamp":1701751535365,"user_tz":-540,"elapsed":4986,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"a5c8004e-ff2f-492a-da77-616b85ebe9c2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# 데이터셋 불러오기: 일반 언어이해 평가(GLUE) 벤치마크 중 하나인 CoLA 데이터셋\n","raw_datasets = load_dataset(\"glue\", \"cola\")\n","raw_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pxd9AnTCtdl6","executionInfo":{"status":"ok","timestamp":1701751537937,"user_tz":-540,"elapsed":2575,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"89bc139e-e9dd-480f-d8c3-b13f17e74530"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 8551\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1043\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1063\n","    })\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","# 모델 로드\n","model_name_or_path = \"bert-base-uncased\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=2)    # COLA dataset의 라벨은 0(unacceptable)과 1(accpetable) 두 가지로 구분됨\n","\n","# 토크나이저 정의\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"sentence\"], truncation=True)\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["c5fc91e5bc604d81a61525556d80a975","26f08597932e40f689c4bb14a7c68115","d12c9e5c424740baa0e58fb8ba57a755","ab2912b290b64d63ae02a1e22fc3dcba","a51c29d1071e4e98b730e8154c4a0232","bd5e8e7ae34849c898b8e20560f7bcb6","b6efc32f543b45e59733fb006d1ca4f4","edfa8184ec0b4921af6c3e121551a18a","c09f69b83dd848d982737694ed067147","0c65adbe34e04e14bd952a5a5509cd13","694aa711691a4ed3a99362a3efb6bfa1"]},"id":"ehjUWBtBBPT-","executionInfo":{"status":"ok","timestamp":1701751540825,"user_tz":-540,"elapsed":2890,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"cd20c895-f789-4257-c93c-62e504f2f04b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fc91e5bc604d81a61525556d80a975"}},"metadata":{}}]},{"cell_type":"code","source":["# 라이브러리 업데이트(세션 재시작 필요)\n","!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"910P9rD3PKpy","executionInfo":{"status":"ok","timestamp":1701751548716,"user_tz":-540,"elapsed":7893,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"6786b0f1-1a44-4945-f503-846470f7e198"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","# 훈련 인자(Arguments)\n","training_args = TrainingArguments(\n","    output_dir='./results',              # output이 저장될 경로\n","    num_train_epochs=1,              # train 시킬 총 epochs\n","    per_device_train_batch_size=16,  # 각 device 당 batch size\n","    per_device_eval_batch_size=64,   # evaluation 시에 batch size\n","    warmup_steps=500,                # learning rate scheduler에 따른 warmup_step 설정\n","    weight_decay=0.01,                 # weight decay\n","    logging_dir='./logs',                 # log가 저장될 경로\n","    do_train=True,                        # train 수행여부\n","    do_eval=True,                        # eval 수행여부\n","    eval_steps=1000,\n","    group_by_length=False,\n",")"],"metadata":{"id":"-UDp6daMBYsj","executionInfo":{"status":"ok","timestamp":1701751548716,"user_tz":-540,"elapsed":11,"user":{"displayName":"­김정현","userId":"07015025296255556159"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","trainer = Trainer(\n","    model,                                                                    # 학습시킬 model\n","    args=training_args,                                                # TrainingArguments을 통해 설정한 arguments\n","    train_dataset=tokenized_datasets[\"train\"],         # training dataset\n","    eval_dataset=tokenized_datasets[\"validation\"], # validation dataset\n","    tokenizer=tokenizer,\n",")\n","\n","# 모델 학습\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"NfBi8UFgCDMJ","executionInfo":{"status":"ok","timestamp":1701751625154,"user_tz":-540,"elapsed":76448,"user":{"displayName":"­김정현","userId":"07015025296255556159"}},"outputId":"37e6a2d4-8255-4ee5-8087-cc9ecfd36383"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='535' max='535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [535/535 01:08, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.546700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=535, training_loss=0.5442507734922605, metrics={'train_runtime': 68.6234, 'train_samples_per_second': 124.608, 'train_steps_per_second': 7.796, 'total_flos': 91092439031580.0, 'train_loss': 0.5442507734922605, 'epoch': 1.0})"]},"metadata":{},"execution_count":21}]}]}