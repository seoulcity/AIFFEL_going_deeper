{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxKFFSX4oNzt"
   },
   "source": [
    "# 한글 폰트 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "9w3yj2Apo2vt"
   },
   "outputs": [],
   "source": [
    "# 한글폰트 설치\n",
    "# !sudo apt-get install -y fonts-nanum\n",
    "# !sudo fc-cache -fv\n",
    "# !rm ~/.cache/matplotlib -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "kaAt6pJDo9zL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 한글 표시 여부 확인\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic' # 나눔바른고딕 적용하기\n",
    "\n",
    "# 예제 데이터\n",
    "heights = [150, 160, 170, 180, 190]  # 키 (cm)\n",
    "weights = [50, 60, 70, 80, 90]       # 몸무게 (kg)\n",
    "\n",
    "# 산점도 그리기\n",
    "plt.scatter(heights, weights)\n",
    "\n",
    "# 제목 및 레이블 추가\n",
    "plt.title(\"키와 몸무게\")\n",
    "plt.xlabel(\"키 (cm)\")\n",
    "plt.ylabel(\"몸무게 (kg)\")\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 외부에서 데이터 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub7A5tEtqXPa"
   },
   "source": [
    "# 데이터 로드 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone git@github.com:songys/Chatbot_data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "BXzWc6nUqZO2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Q                         A  label\n",
      "0                       12시 땡!                하루가 또 가네요.      0\n",
      "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
      "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
      "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
      "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
      "...                        ...                       ...    ...\n",
      "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
      "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
      "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
      "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
      "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
      "\n",
      "[11823 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 파일 읽기\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 지정\n",
    "file_path = \"Chatbot_data/ChatbotData.csv\" # 파일 경로 입력\n",
    "\n",
    "# CSV 파일을 데이터프레임으로 불러오기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터프레임 확인\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Q' 컬럼의 데이터를 리스트로 옮기기\n",
    "Q_column_list = df['Q'].tolist()\n",
    "A_column_list = df['A'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ['12시 땡!', '가스비 비싼데 감기 걸리겠어', '간만에 떨리니까 좋더라', '감정컨트롤을 못하겠어', '개강룩 입어볼까'], 문장갯수: 11823\n",
      "A: ['하루가 또 가네요.', '따뜻하게 사세요!', '떨리는 감정은 그 자체로 소중해요.', '그건 습관이에요.', '개시해보세요.'], 문장갯수: 11823\n"
     ]
    }
   ],
   "source": [
    "print(f'Q: {Q_column_list[0:100:20]}, 문장갯수: {len(Q_column_list)}')\n",
    "print(f'A: {A_column_list[0:100:20]}, 문장갯수: {len(A_column_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "U51lFcTkp0FM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 소문자 변환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 공백 제거\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence) # 글자, 숫자, 구두점 외 특수문자 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ['12시 땡!', '가스비 비싼데 감기 걸리겠어', '간만에 떨리니까 좋더라', '감정컨트롤을 못하겠어', '개강룩 입어볼까'], 문장갯수: 11232\n",
      "A: ['하루가 또 가네요.', '따뜻하게 사세요!', '떨리는 감정은 그 자체로 소중해요.', '그건 습관이에요.', '개시해보세요.'], 문장갯수: 11232\n"
     ]
    }
   ],
   "source": [
    "# 질의 응답 각 코퍼스별 전처리\n",
    "Q_preprocessed = list(map(preprocess_sentence, Q_column_list))\n",
    "A_preprocessed = list(map(preprocess_sentence, A_column_list))\n",
    "\n",
    "print(f'Q: {Q_sentence[0:100:20]}, 문장갯수: {len(Q_sentence)}')\n",
    "print(f'A: {A_sentence[0:100:20]}, 문장갯수: {len(A_sentence)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size:  591\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_sentence_count = len(Q_preprocessed)\n",
    "test_sentence_count = total_sentence_count // 20\n",
    "\n",
    "print(\"Test Size: \", test_sentence_count)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터 분리\n",
    "Q_sentence = Q_preprocessed[:-test_sentence_count]\n",
    "A_sentence = A_preprocessed[:-test_sentence_count]\n",
    "test_Q_sentences = Q_preprocessed[-test_sentence_count:]\n",
    "test_A_sentences = A_preprocessed[-test_sentence_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "2MBWyCWOpMCt"
   },
   "outputs": [],
   "source": [
    "# 한국어 관련 라이브러리\n",
    "# !curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "XmcoZZg3rR_d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4de921b81bf403592d1a98927d4cfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0ea6b416624a7f85501962ec74be8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코퍼스 토큰화\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mecab = Mecab()\n",
    "def make_corpus(sentences, tokenizer):\n",
    "    corpus = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokens = tokenizer.morphs(sentence)\n",
    "        corpus.append(tokens)\n",
    "    return corpus\n",
    "\n",
    "# 예제 문장 리스트\n",
    "Q_example = [\"이것은 예제 문장입니다.\", \"형태소 분석을 시도해 봅시다.\"]\n",
    "A_example = [\"또 다른 예제 문장입니다.\", \"분석이 잘 되었으면 좋겠네요.\"]\n",
    "\n",
    "Q_ex_tokenized = make_corpus(Q_example, mecab)\n",
    "A_ex_tokenized = make_corpus(A_example, mecab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['이것', '은', '예제', '문장', '입니다', '.'],\n",
       "  ['형태소', '분석', '을', '시도', '해', '봅시다', '.']],\n",
       " [['또', '다른', '예제', '문장', '입니다', '.'],\n",
       "  ['분석', '이', '잘', '되', '었', '으면', '좋', '겠', '네요', '.']])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_ex_tokenized, A_ex_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ca17b2e50c4ffa8f4a24dfc962999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7a6cfb68fc48c5a0b4ecf78a971676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_tokenized = make_corpus(Q_sentence, mecab)\n",
    "A_tokenized = make_corpus(A_sentence, mecab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['12', '시', '땡', '!'],\n",
       "  ['가스', '비', '비싼데', '감기', '걸리', '겠', '어'],\n",
       "  ['간만에', '떨리', '니까', '좋', '더라'],\n",
       "  ['감정', '컨트롤', '을', '못', '하', '겠', '어'],\n",
       "  ['개강', '룩', '입', '어', '볼까']],\n",
       " [['하루', '가', '또', '가', '네요', '.'],\n",
       "  ['따뜻', '하', '게', '사세요', '!'],\n",
       "  ['떨리', '는', '감정', '은', '그', '자체', '로', '소중', '해요', '.'],\n",
       "  ['그건', '습관', '이', '에요', '.'],\n",
       "  ['개시', '해', '보', '세요', '.']])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_tokenized[0:100:20], A_tokenized[0:100:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어휘 대체(Lexical Substitution)을 통한 데이터 증강"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[한국어 사전 훈련된 다운로드 링크](https://drive.google.com/file/d/0B0ZXk88koS2KbDhXdWg1Q2RydlU/view?resourcekey=0-Dq9yyzwZxAqT3J02qvnFwg)\n",
    "\n",
    "[위 링크가 포함된 워드 벡터 깃헙저장소](https://github.com/Kyubyong/wordvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# \b한국어 사전훈련 모델 저장소로부터, FastText 형식의 벡터파일을 다운로드하였음\n",
    "# 사전 훈련된 FastText 모델의 경로를 지정합니다.\n",
    "model_path = 'ko.vec'\n",
    "\n",
    "# 모델을 로드합니다.\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.2242e-02 -6.9223e-02  2.6350e-01  2.6930e-02  2.7465e-01 -5.7484e-02\n",
      "  1.1657e-01 -1.0736e-01  2.6542e-01 -1.5600e-01  4.8601e-01  6.3728e-01\n",
      "  5.7949e-01  2.1420e-01 -3.2206e-02 -9.1503e-03  2.0928e-01 -8.1857e-02\n",
      " -2.6783e-01 -2.5602e-01  1.4733e-01  4.5259e-01  3.6965e-01  2.4644e-01\n",
      " -4.4918e-02 -6.7232e-02  3.1724e-02  3.3469e-01  2.6623e-01 -1.1605e-01\n",
      " -1.5161e-02  1.0318e-01  1.4193e-01 -7.9796e-02  1.5111e-02  1.0474e-01\n",
      " -2.3739e-01 -1.1473e-01 -5.4767e-02  8.9843e-02  3.1133e-01  3.2850e-01\n",
      "  9.2288e-02 -1.3007e-01 -4.7345e-01 -4.1861e-01 -2.1817e-01 -1.6687e-02\n",
      "  3.4634e-01  1.1898e-01  2.5232e-01  5.3454e-03  9.8491e-02  1.4123e-01\n",
      "  2.8660e-02 -1.1567e-01  5.5575e-01 -1.4759e-01  2.7344e-01 -2.9719e-01\n",
      "  7.8230e-02 -2.1698e-01 -1.9905e-01  3.0314e-01 -4.5031e-02  1.6996e-01\n",
      " -3.5892e-01 -2.6847e-01  1.4510e-01 -2.0968e-01 -1.1155e-01 -2.4789e-01\n",
      "  7.3840e-02 -1.5958e-01 -5.4518e-01 -2.1918e-01  4.6502e-01 -4.5190e-01\n",
      " -3.0823e-02 -5.2310e-02 -3.0539e-01 -3.2815e-01  4.9398e-01 -6.1352e-02\n",
      "  3.5518e-01 -3.2516e-02 -2.5340e-01  9.9453e-02 -3.8745e-01  2.8348e-01\n",
      "  2.0849e-01  3.5381e-01  4.9125e-01  2.0817e-01 -1.6912e-01 -1.7050e-01\n",
      " -3.3246e-01 -2.8901e-02 -3.5438e-02 -6.2448e-01  2.0265e-01 -3.1291e-01\n",
      "  2.6814e-01 -1.7607e-02 -7.5575e-02 -3.5508e-01  2.6724e-02 -2.9611e-01\n",
      " -2.8780e-01 -1.5216e-01 -1.6836e-02  1.6816e-02  4.3019e-01 -3.3865e-02\n",
      " -3.1984e-01  2.1714e-01  5.7882e-02 -5.3531e-02  2.3571e-01  1.6869e-01\n",
      "  5.7575e-02 -1.8389e-01  1.4210e-01 -4.0831e-02 -2.1561e-01 -7.0739e-02\n",
      " -9.4748e-02  6.9231e-02 -1.1031e-01  6.3621e-02  4.0665e-01 -1.0841e-01\n",
      "  1.3543e-01  3.1294e-01 -6.0529e-03 -1.6539e-01 -3.2659e-01  4.8248e-03\n",
      "  1.1890e-01 -1.0454e-01 -2.0947e-01 -1.3760e-01 -1.9147e-01 -1.0139e-01\n",
      "  2.7186e-01 -7.4093e-02  4.4072e-01  3.1493e-01  8.2520e-02  1.4896e-01\n",
      " -1.9173e-01  3.0816e-01 -3.1060e-01 -1.9823e-01 -4.9816e-02 -2.6061e-01\n",
      " -5.0265e-02 -7.9298e-02 -1.5639e-01 -5.8595e-02 -9.3044e-02  1.3687e-01\n",
      " -1.3375e-01  5.3847e-02  2.5587e-01  9.5366e-03  1.9998e-01 -1.1988e-01\n",
      "  1.4942e-01 -2.1318e-01  1.3337e-04 -1.8778e-01 -1.7056e-01 -1.8550e-01\n",
      "  2.6642e-01  2.6330e-01  1.9200e-01  4.5847e-01  2.3541e-01 -2.1610e-01\n",
      "  7.4057e-02 -2.8515e-01 -1.7574e-01  9.6531e-02  1.9998e-01  1.0503e-01\n",
      "  6.4972e-02 -4.4216e-02  2.6575e-01 -7.3315e-02 -1.9885e-01 -1.3322e-01\n",
      "  2.9249e-01  3.5137e-01  9.2284e-02  1.4890e-01  6.4545e-02  8.2889e-02\n",
      " -3.0227e-02  5.7437e-02]\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 단어 벡터를 얻습니다. 예를 들어, '사랑'이라는 단어에 대한 벡터를 조회합니다.\n",
    "word_vector = model['사랑']\n",
    "\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('사랑과', 0.6912475228309631),\n",
       " ('그리움', 0.66273033618927),\n",
       " ('이별', 0.6524810194969177),\n",
       " ('그대', 0.649117112159729),\n",
       " ('연인', 0.6449648141860962),\n",
       " ('슬픔', 0.6445863246917725),\n",
       " ('외로움', 0.6422537565231323),\n",
       " ('사랑이', 0.6219196915626526),\n",
       " ('첫사랑', 0.6168366074562073),\n",
       " ('애정', 0.6153576970100403)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_word = model.most_similar('사랑')\n",
    "similar_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def lexical_sub(sentence, word_vectors):\n",
    "    \"\"\"\n",
    "    문장의 임의의 단어를 유사한 단어로 대체합니다.\n",
    "    \n",
    "    :param sentence: 원본 문장 (string)\n",
    "    :param word_vectors: word2vec 모델의 word vectors\n",
    "    :return: 변형된 문장 (string)\n",
    "    \"\"\"\n",
    "    selected_tok = random.choice(sentence)\n",
    "\n",
    "    result = \"\"\n",
    "    for tok in sentence:\n",
    "        if tok == selected_tok:\n",
    "            # 선택된 토큰에 대한 유사한 단어 찾기\n",
    "            try:\n",
    "                # 유사한 단어로 대체\n",
    "                similar_word = word_vectors.most_similar(tok)[0][0]\n",
    "                result += similar_word + \" \"\n",
    "            except KeyError:\n",
    "                # 단어가 word2vec 모델에 없는 경우, 원본 단어를 사용\n",
    "                result += tok + \" \"\n",
    "        else:\n",
    "            result += tok + \" \"\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: ['사랑', '한다고', '말', '해', '주', '면', '뭐', '가', '덧나', '나']\n",
      "To: 사랑과 한다고 말 해 주 면 뭐 가 덧나 나\n"
     ]
    }
   ],
   "source": [
    "# 예시 사용\n",
    "sample_sentence = Q_tokenized[10000]\n",
    "\n",
    "augmented_sentence = lexical_sub(sample_sentence, model)\n",
    "print(\"From:\", sample_sentence)\n",
    "print(\"To:\", augmented_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb42834acb4a5a87b390983b85fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying Lexical Substitution:   0%|          | 0/11232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb23c9e6b114f9fb7cb72fa0c571427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying Lexical Substitution:   0%|          | 0/11232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_lexical_substitution(Q_tokenized, model):\n",
    "    augmented_sentences = []  # 결과를 저장할 리스트\n",
    "\n",
    "    for sample_sentence in tqdm(Q_tokenized, desc=\"Applying Lexical Substitution\"):\n",
    "        # 각 문장에 대해 lexical_sub 함수를 적용\n",
    "        augmented = lexical_sub(sample_sentence, model)\n",
    "        # 결과를 augmented_sentences 리스트에 추가\n",
    "        augmented_sentences.append(augmented)\n",
    "\n",
    "    return augmented_sentences\n",
    "    \n",
    "# 함수 사용\n",
    "augmented_Q = apply_lexical_substitution(Q_tokenized, model)\n",
    "augmented_A = apply_lexical_substitution(A_tokenized, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11232, 11232, 11232, 11232]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: len(x), [Q_tokenized, augmented_Q, A_tokenized, augmented_A]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33696, 33696)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_Q = Q_tokenized + augmented_Q + Q_tokenized\n",
    "syn_A = A_tokenized + A_tokenized + augmented_A\n",
    "\n",
    "len(syn_Q), len(syn_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '12', '시', '땡', '!', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# 아래와 같이 코퍼스 전체에 시작 및 종료 토큰 추가\n",
    "sample_data = [\"12\", \"시\", \"땡\", \"!\"]\n",
    "\n",
    "print([\"<start>\"] + sample_data + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '시', '땡', '!', '<end>']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['시', '땡', '!']\n",
    "data_added = [\"<start>\"] + data + [\"<end>\"]\n",
    "data_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d19a5265b9347078e501cc42298206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding Tokens:   0%|          | 0/33696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816fcc328c5b4e1793cb63c13dbf412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding Tokens:   0%|          | 0/33696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시작 및 종료 토큰을 추가하는 함수\n",
    "def add_tokens(data):\n",
    "    # 새로운 빈 리스트 생성\n",
    "    result = []\n",
    "    # tqdm을 사용하여 진행 상황을 표시\n",
    "    for sentence in tqdm(data, desc=\"Adding Tokens\"):\n",
    "        sentence_list = list(sentence)  # 문자열을 리스트로 변환\n",
    "        if sentence_list[0] != \"<start>\":\n",
    "            sentence_list.insert(0, \"<start>\")  # 시작 토큰 추가\n",
    "        if sentence_list[-1] != \"<end>\":\n",
    "            sentence_list.append(\"<end>\")  # 종료 토큰 추가\n",
    "        result.append(sentence_list)\n",
    "    return result\n",
    "\n",
    "# syn_Q와 syn_A에 함수 적용\n",
    "processed_syn_Q = add_tokens(syn_Q)\n",
    "processed_syn_A = add_tokens(syn_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '거지', '됐', '어', '<end>']\n",
      "['<start>', '밥', '사', '줄', '친구', '를', '찾', '아', '보', '세요', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 (옵션)\n",
    "print(processed_syn_Q[100])\n",
    "print(processed_syn_A[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_train shape: (33696, 50)\n",
      "dec_train shape: (33696, 50)\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 단어 임베딩 층 정의\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# syn_Q와 syn_A를 결합\n",
    "combined_data = processed_syn_Q + processed_syn_A\n",
    "\n",
    "# Tokenizer를 사용하여 단어 사전을 구축하고 단어 사전의 크기를 10,000으로 제한\n",
    "vocab_size = 10000\n",
    "TOKENIZER = Tokenizer(num_words=vocab_size, filters='', oov_token=\"<oov>\")\n",
    "TOKENIZER.fit_on_texts(combined_data)\n",
    "\n",
    "# 문장을 숫자 시퀀스로 변환\n",
    "sequences_Q = TOKENIZER.texts_to_sequences(processed_syn_Q)\n",
    "sequences_A = TOKENIZER.texts_to_sequences(processed_syn_A)\n",
    "\n",
    "# 패딩을 추가하여 시퀀스의 길이를 50으로 맞춥니다.\n",
    "MAX_LEN = 50\n",
    "enc_train = pad_sequences(sequences_Q, maxlen=MAX_LEN, padding='post')\n",
    "dec_train = pad_sequences(sequences_A, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# enc_train과 dec_train을 출력합니다.\n",
    "print(\"enc_train shape:\", enc_train.shape)\n",
    "print(\"dec_train shape:\", dec_train.shape)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence Q: [  3 909  18  31  17  42 827  13  22 265  15 828   4   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Decoded Text Q: <start> sns 보 면 나 만 빼 고 다 행복 해 보여 <end> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "\n",
      "Original Sequence A: [   3 3346    7    8 1196  443    5    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Decoded Text A: <start> 자랑 하 는 자리 니까요 . <end> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "# index_word 사전 생성\n",
    "index_word = {i: word for word, i in TOKENIZER.word_index.items()}\n",
    "\n",
    "# 숫자 시퀀스를 문장으로 변환하는 함수\n",
    "def sequence_to_text(sequence):\n",
    "    return ' '.join([index_word.get(i, '?') for i in sequence])\n",
    "\n",
    "# 예시 데이터 포인트 변환\n",
    "sample_index = 10  # 예시 인덱스, 이 값을 변경하여 다른 데이터 포인트를 선택할 수 있습니다.\n",
    "sample_sequence_Q = enc_train[sample_index]\n",
    "sample_sequence_A = dec_train[sample_index]\n",
    "\n",
    "# 변환된 문장 출력\n",
    "print(\"Original Sequence Q:\", sample_sequence_Q)\n",
    "print(\"Decoded Text Q:\", sequence_to_text(sample_sequence_Q))\n",
    "print(\"\\nOriginal Sequence A:\", sample_sequence_A)\n",
    "print(\"Decoded Text A:\", sequence_to_text(sample_sequence_A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 배치 사이즈 및 입력데이터 텐서화\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련\n",
    "\n",
    "## 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "## 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 1\n",
    "> d_model: 368\n",
    "> n_heads: 8\n",
    "> d_ff: 1024\n",
    "> dropout: 0.2\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 1000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 포지셔널 인코딩\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "        \n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table\n",
    "\n",
    "# 마스크 생성 함수\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "# 멀티헤드 어텐션\n",
    "# Multi Head Attention 구현\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights\n",
    "\n",
    "# Position-wise Feed Forward Network 구현\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "# 디코더 레이어\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "# 인코더\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "\n",
    "# 디코더\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 모델\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "transformer = Transformer(\n",
    "    n_layers=1,\n",
    "    d_model=368,\n",
    "    n_heads=8,\n",
    "    d_ff=1024,\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    pos_len=200,\n",
    "    dropout=0.2,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "d_model = 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 스케쥴러\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=1000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32) # step을 float32로 변환\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 단계 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습율과 최적화 도구\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)\n",
    "\n",
    "# 손실함수 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7439d3797c42afa11f0ccd9a3adeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1: 평균 손실 = 3.914339542388916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59f87d41cb64bd5b3adca4790f7836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 2: 평균 손실 = 2.6461057662963867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c320f31bf74dc380c330ec4aca38f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 3: 평균 손실 = 2.0870895385742188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e2f721b0924602adb51aafa5feef81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 4: 평균 손실 = 1.5431286096572876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e5286db1a64fd7bd8b5caf5cd1144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 5: 평균 손실 = 1.1386432647705078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd50d3b56e44a80b6f07194584e33ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 6: 평균 손실 = 0.8715028762817383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84a2c170b1c417cbb1f263c607119de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 7: 평균 손실 = 0.6809173822402954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351f246ca3ce460e8ecfd74cd9fdd249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 8: 평균 손실 = 0.5388385653495789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09df45b429b4475e9d39595e9bd60554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 9: 평균 손실 = 0.4346868097782135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbe098bd93d46a9815af069da95d75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 10: 평균 손실 = 0.35510218143463135\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    \n",
    "    for (batch, (src, tgt)) in enumerate(train_dataset):\n",
    "        batch_loss, _, _, _ = train_step(src, tgt, transformer, optimizer)  # 첫 번째 요소만 추출\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        # 진행률 표시 갱신\n",
    "        tqdm_bar.update(1)\n",
    "        tqdm_bar.set_postfix(Batch_loss=batch_loss.numpy(), Avg_loss=(total_loss / (batch + 1)))\n",
    "    \n",
    "    tqdm_bar.close()\n",
    "    print(f\"에포크 {epoch + 1}: 평균 손실 = {total_loss / dataset_count}\")\n",
    "    transformer.save_weights(f\"model_checkpoint_epoch_{epoch + 1}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 측정\n",
    "\n",
    "- BLEU Score를 계산하는 calculate_bleu() 함수도 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 함수\n",
    "# TensorFlow Tokenizer용 bos_id, eos_id 가져오기\n",
    "bos_id = TOKENIZER.word_index['<start>']\n",
    "eos_id = TOKENIZER.word_index['<end>']\n",
    "\n",
    "# TensorFlow Tokenizer용 decode_ids 함수\n",
    "def decode_ids(tokenizer, sequence):\n",
    "    return tokenizer.sequences_to_texts([sequence])[0]\n",
    "    \n",
    "def translate(tokens, model, src_tokenizer, tgt_tokenizer):\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=MAX_LEN,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([bos_id], 0)\n",
    "    for i in range(MAX_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if eos_id == predicted_id: \n",
    "            result = decode_ids(tgt_tokenizer, ids) \n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = decode_ids(tgt_tokenizer, ids) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "# BLEU 점수 계산 함수 수정\n",
    "def eval_bleu_single(model, src_sentence, tgt_sentence, src_tokenizer, tgt_tokenizer, mecab, verbose=True):\n",
    "    # Mecab을 사용한 토크나이징\n",
    "    src_tokens_mecab = mecab.morphs(src_sentence)\n",
    "    tgt_tokens_mecab = mecab.morphs(tgt_sentence)\n",
    "    \n",
    "    # 시작 및 종료 토큰 추가\n",
    "    src_sentence = \"<start> \" + src_sentence + \" <end>\"\n",
    "    tgt_sentence = \"<start> \" + tgt_sentence + \" <end>\"\n",
    "\n",
    "    # TensorFlow Tokenizer를 사용한 숫자 시퀀스 변환\n",
    "    src_tokens = src_tokenizer.texts_to_sequences([' '.join(src_tokens_mecab)])[0]\n",
    "    tgt_tokens = tgt_tokenizer.texts_to_sequences([' '.join(tgt_tokens_mecab)])[0]\n",
    "\n",
    "    if (len(src_tokens) > MAX_LEN): return None\n",
    "    if (len(tgt_tokens) > MAX_LEN): return None\n",
    "\n",
    "    reference_mecab = ' '.join(tgt_tokens_mecab)  # Mecab으로 토크나이즈된 참조 문장\n",
    "    reference = tgt_sentence.split()\n",
    "    candidate = translate(src_tokens, model, src_tokenizer, tgt_tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Real (Tokenized): \", reference_mecab)  # 수정된 부분\n",
    "        print(\"Real (Original): \", reference)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 좋아하는 여자한테 선물해도 괜찮을까? <end>\n",
      "Model Prediction:  ['사', '람', '마', '다', '다', '르', '겠', '지', '만', '괜', '찮', '아', '요', '.']\n",
      "Real (Tokenized):  좋 아 할 거 예요 .\n",
      "Real (Original):  ['<start>', '좋아할', '거예요.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 10\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 좋아했던 사람도 금방 잊을 수 있을까. <end>\n",
      "Model Prediction:  ['좋', '은', '사', '람', '에', '대', '한', '시', '간', '이', '필', '요', '한', '거', '예', '요', '.']\n",
      "Real (Tokenized):  아무래도 시간 이 필요 하 겠 죠 .\n",
      "Real (Original):  ['<start>', '아무래도', '시간이', '필요하겠죠.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 50\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 짝남 관련 악몽을 꿔. <end>\n",
      "Model Prediction:  ['복', '소', '중', '해', '요', '.']\n",
      "Real (Tokenized):  안 좋 은 일 이 라도 있 었 나 봐요 .\n",
      "Real (Original):  ['<start>', '안좋은', '일이라도', '있었나봐요.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 100\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 짝남이 나한테 여지준 것 같아. <end>\n",
      "Model Prediction:  ['인', '고', '마', '음', '고', '치', '지', '마', '요', '<', '/', 's', '>']\n",
      "Real (Tokenized):  오해 가 아니 라면 나쁜 분 이 네요 .\n",
      "Real (Original):  ['<start>', '오해가', '아니라면', '나쁜', '분이네요.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 150\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 짝남이랑 저녁에 보기로 했는데 연락이 없다. <end>\n",
      "Model Prediction:  ['즐', '거', '운', '사', '랑', '하', '는', '고', '인', '가', '봐', '요', '.']\n",
      "Real (Tokenized):  한 번 만 더 연락 해 보 는 건 어떨까 요 .\n",
      "Real (Original):  ['<start>', '한', '번만', '더', '연락해보는', '건', '어떨까요.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 200\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  <start> 짝녀 오랫동안 멀리서 지켜보기만 하고 있습니다. <end>\n",
      "Model Prediction:  ['고', '백', '해', '보', '는', '게', '좋', '고', '것', '같', '네', '요', '.']\n",
      "Real (Tokenized):  뒤 에서 만 지켜보 는 게 힘들 었 겠 어요 .\n",
      "Real (Original):  ['<start>', '뒤에서만', '지켜보는게', '힘들었겠어요.', '<end>']\n",
      "Score: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 250\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_Q_sentences[test_idx], \n",
    "                 test_A_sentences[test_idx], \n",
    "                 TOKENIZER,\n",
    "                 TOKENIZER,\n",
    "                 mecab)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOb+a3dHFDinwMizJL2pqJ/",
   "provenance": [
    {
     "file_id": "1TdtOSUMl_jcE6OwwzWlUrtpEYVnj90wQ",
     "timestamp": 1701220391104
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
